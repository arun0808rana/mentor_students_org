<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <!-- <form>
        <input type="email" name="email" class="email">
        <input type="password" name="password" class="password">
        <button class="submit"></button>
    </form>
    <video autoplay loop muted></video>
    <script src="main.js"></script>

    <script>
        const constraints = {
            video: true
        };
    
        function handleSuccess(stream) {
            document.querySelector('video').srcObject = stream;
        }
    
        function handleError(error) {
            console.log('getDisplayMedia error: ', error);
        }
    
        navigator.mediaDevices.getDisplayMedia(constraints)
                .then(handleSuccess)
                .catch(handleError);
    </script> -->


    <video id="video" width="320" height="240" autoplay></video>
    <br>
    <button id="start-camera">Start Camera</button>
    <button class="stop-camera">Stop Camera</button>
    <button id="start-record">Start Recording</button>
    <button id="stop-record">Stop Recording</button>
    <a id="download-video" download="test.webm">Download Video</a>

    <script>
        let camera_button = document.querySelector("#start-camera");
        let video = document.querySelector("#video");
        let start_button = document.querySelector("#start-record");
        let stop_button = document.querySelector("#stop-record");
        let download_link = document.querySelector("#download-video");
        const stopCameraBtn = document.querySelector('.stop-camera');

        let camera_stream = null;
        let media_recorder = null;
        let blobs_recorded = [];

        let isCameraOn = false;

        function stopCamera() {
            camera_stream.getTracks().forEach(track => track.stop());
            video.srcObject = null;
            isCameraOn = false;
        }

        camera_button.addEventListener('click', async function () {
            if(isCameraOn){
                return;
            }
            camera_stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
            video.srcObject = camera_stream;
            isCameraOn = true;
        });

        stopCameraBtn.onclick = event => {
            if(!isCameraOn){
                return;
            }
            stopCamera();
        }

        start_button.addEventListener('click', function () {
            if(!isCameraOn){
                return;
            }
            // set MIME type of recording as video/webm
            media_recorder = new MediaRecorder(camera_stream, { mimeType: 'video/webm' });

            // event : new recorded video blob available 
            media_recorder.addEventListener('dataavailable', function (e) {
                blobs_recorded.push(e.data);
            });

            // event : recording stopped & all blobs sent
            media_recorder.addEventListener('stop', function () {
                // create local object URL from the recorded video blobs
                let video_local = URL.createObjectURL(new Blob(blobs_recorded, { type: 'video/webm' }));
                download_link.href = video_local;
            });

            // start recording with each recorded blob having 1 second video
            media_recorder.start(1000);
        });

        stop_button.addEventListener('click', function () {
            if(!isCameraOn){
                return;
            }
            media_recorder.stop();
            stopCamera();
        });
    </script>
</body>

</html>

<!-- https://www.encora.com/insights/capturing-audio-video-with-webrtc -->